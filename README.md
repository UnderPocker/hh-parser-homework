# Pipeline обработки данных HeadHunter

Проект для обработки данных из CSV файла с использованием паттерна проектирования "Цепочка ответственности" (Chain of Responsibility).

## Описание

Проект реализует пайплайн обработки данных, который:
1. Загружает данные из CSV файла
2. Очищает данные (удаляет дубликаты, лишние колонки)
3. Обрабатывает пропущенные значения
4. Кодирует категориальные переменные
5. Выполняет feature engineering
6. Разделяет данные на признаки (X) и целевую переменную (y)
7. Сохраняет результаты в .npy файлы

## Установка

```bash
pip install -r requirements.txt
```

## Использование

```bash
python app.py path/to/hh.csv
```

После выполнения рядом с входным файлом будут созданы:
- `x_data.npy`
- `y_data.npy`

## Архитектура

Проект использует паттерн **Chain of Responsibility**, где каждый обработчик:
- Наследуется от `BaseHandler`
- Реализует метод `process()` для обработки данных
- Может передать данные следующему обработчику в цепочке

### Обработчики:

1. **LoadDataHandler** - загрузка данных из CSV
2. **CleanDataHandler** - очистка данных
3. **HandleMissingValuesHandler** - обработка пропущенных значений
4. **EncodeCategoricalHandler** - кодирование категориальных переменных
5. **FeatureEngineeringHandler** - создание новых признаков
6. **SplitDataHandler** - разделение на X и y
7. **SaveDataHandler** - сохранение в .npy файлы

## Best Practices

- Type hints для всех функций
- Docstrings в формате Google Style
- Логирование операций
- Обработка ошибок
- Разделение ответственности (SRP)
- PEP 8 стиль кода
- Модульная структура
